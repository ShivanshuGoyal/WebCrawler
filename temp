
    def store_data_util(self, url, depth):
        
        # print 'Current url: ' + url
        if url[0:8] == 'https://':
            return []
            
        base = self.get_base(url)
        base_domain = self.get_base_domain(url)
        data = self.get_data(url)
        self.database.store({'url': url, 'data': data['info']})
        if depth > 5:
            return data['links']
        else:
            for link in data['links']:
                if type(link)!=str or link[0:1] == '#' or link[0:8] == 'https://' or self.crawledUrls.has_key(url.lower()) or link.rfind('javascript:void(0)')!=-1:
                    continue
                link = link.strip()
                
                if len(link)!=0:
                    if(link[0]=='/'):
                        link = base_domain + link
                    elif (link[0:7] != 'http://'):
                        link = base + link
                
                try:
                    links = self.store_data(link, depth+1, url)
                except urllib.HTTPError, e:
                    print 'HTTP Error at link: ' + link
                except urllib.URLError, e:
                    print 'URL error for link "' + link + '"'

            self.crawledUrls[url.lower()] = True
            self.urlDb.store(url.lower() + "\n")
            
            return data['links']
    */